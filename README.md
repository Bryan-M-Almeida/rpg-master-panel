# ğŸ² RPG Master Panel

**RPG Master Panel** Ã© uma aplicaÃ§Ã£o web que auxilia mestres de RPG a gerenciar sessÃµes de forma prÃ¡tica e eficiente. Com ela, Ã© possÃ­vel organizar personagens, cenÃ¡rios e eventos, mantendo o controle total da narrativa.

---

# Fotos e vÃ­deos

![rpg](https://github.com/user-attachments/assets/ada6a3c5-c435-4142-a1a8-971981911e31)

![rpg 2](https://github.com/user-attachments/assets/1b0b1925-1c08-40d2-a1dc-1c80ab7affde)

![rpg 3](https://github.com/user-attachments/assets/8b8c327e-c213-4aef-9ed5-63b66cf776e1)

![rpg 4](https://github.com/user-attachments/assets/b4647c6b-e7ac-4304-986c-ecda2b4904f4)

![rpg 5](https://github.com/user-attachments/assets/e9658fc2-2daa-4df3-bac5-368ef9987107)

![gerando](https://github.com/user-attachments/assets/6244fa53-1f18-48d0-803b-7c043eaadc1d)

![rpg 6](https://github.com/user-attachments/assets/aaf07f7f-8c05-49ae-b472-cbae4bb7e0a7)

---

# ğŸš€ Funcionalidades

- ğŸ“‹ Cadastro e gerenciamento de personagens
- ğŸ—ºï¸ OrganizaÃ§Ã£o de cenÃ¡rios e locais
- ğŸ“… Planejamento de eventos e sessÃµes
- ğŸ“ AnotaÃ§Ãµes rÃ¡pidas durante o jogo
- ğŸ”’ Controle de acesso para diferentes usuÃ¡rios

---

# ğŸ› ï¸ Tecnologias Utilizadas

- **Express** para o backend
- JS
- CSS
- HTML
- IA local (Ollama)

---

# âš™ï¸ InstalaÃ§Ã£o e Uso
   ```bash
1. Clone o repositÃ³rio:
   git clone https://github.com/Bryan-M-Almeida/rpg-master-panel.git

2. Navegue atÃ© o diretÃ³rio do projeto:
  cd rpg-master-panel

3. Instale as dependÃªncias:
  npm install

4. Inicie o servidor:
  npm start

5. Acesse a aplicaÃ§Ã£o em http://localhost:3000
```
---

# ğŸ§  IntegraÃ§Ã£o com IA Local (Ollama)

Este projeto suporta geraÃ§Ã£o de conteÃºdo via IA local, utilizando o Ollama, sem depender de APIs externas ou serviÃ§os pagos.

# âœ… Requisitos

Ollama instalado

Um modelo baixado (ex: llama3, mistral, codellama)

Projeto rodando localmente

# ğŸš€ Como Usar a IA Ollama

 ```bash

# Instale o Ollama (caso ainda nÃ£o tenha):

curl -fsSL https://ollama.com/install.sh | sh

# Baixe um modelo (exemplo com o LLaMA 3):

ollama pull llama3

# Inicie o modelo:

ollama run llama3
Isso vai iniciar o servidor local.

# Resultado:
A IA vai gerar a histÃ³ria do seu personagem.
```
---

# ğŸ“Œ ContribuiÃ§Ãµes
ContribuiÃ§Ãµes sÃ£o bem-vindas! Sinta-se Ã  vontade para abrir issues ou enviar pull requests.
---

# ğŸ“„ LicenÃ§a
Este projeto estÃ¡ licenciado sob a MIT License.
